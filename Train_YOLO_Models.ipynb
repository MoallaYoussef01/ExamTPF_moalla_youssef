{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoallaYoussef01/ExamTPF_moalla_youssef/blob/main/Train_YOLO_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "cfaWho47RGDf",
        "outputId": "f56eba9c-10fd-43cf-d48d-ef02f52bbbca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Nov 29 12:37:15 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eDhuvzDfIFS"
      },
      "source": [
        "# 2.&nbsp;Upload Image Dataset and Prepare Training Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZW_0c110fOiz"
      },
      "source": [
        "upload the dataset and prepare it for training with YOLO. split the dataset into train and validation folders and generate the configuration file for training the model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 Split images into train and validation folders"
      ],
      "metadata": {
        "id": "m7Iz9eBzW5zm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "z8O6z-wVcPEF"
      },
      "outputs": [],
      "source": [
        "# Unzip images to a custom data folder\n",
        "!unzip -q /content/data.zip -d /content/custom_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/train_val_split.py https://raw.githubusercontent.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/refs/heads/main/utils/train_val_split.py\n",
        "\n",
        "# TO DO: Improve robustness of train_val_split.py script so it can handle nested data folders, etc\n",
        "!python train_val_split.py --datapath=\"/content/custom_data\" --train_pct=0.9"
      ],
      "metadata": {
        "id": "8X62eFTugosf",
        "collapsed": true,
        "outputId": "554fe068-bc2a-43d0-b2d8-f06e9081153d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-29 12:41:51--  https://raw.githubusercontent.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/refs/heads/main/utils/train_val_split.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3203 (3.1K) [text/plain]\n",
            "Saving to: ‚Äò/content/train_val_split.py‚Äô\n",
            "\n",
            "/content/train_val_ 100%[===================>]   3.13K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-11-29 12:41:51 (62.7 MB/s) - ‚Äò/content/train_val_split.py‚Äô saved [3203/3203]\n",
            "\n",
            "Number of image files: 2755\n",
            "Number of annotation files: 2755\n",
            "Images moving to train: 2479\n",
            "Images moving to validation: 276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.&nbsp;Install Requirements (Ultralytics)\n",
        "\n",
        "Next, we'll install the Ultralytics library in this Google Colab instance. This Python library will be used to train the YOLO model."
      ],
      "metadata": {
        "id": "B2L2qGCJzwY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "EMEDk5byzxY5",
        "collapsed": true,
        "outputId": "3993559e-991d-4c05-b3ae-a1b0963ac5f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.3.233)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.18 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.18)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuZoMkSFN9XG"
      },
      "source": [
        "# 5.&nbsp;Configure Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's one last step before we can run training: we need to create the Ultralytics training configuration YAML file. This file specifies the location of your train and validation data, and it also defines the model's classes. An example configuration file model is available [here](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco128.yaml).\n",
        "\n",
        "Run the code block below to automatically generate a `data.yaml` configuration file. Make sure you have a labelmap file located at `custom_data/classes.txt`. If you used Label Studio or one of my pre-made datasets, it should already be present. If you assembled the dataset another way, you may have to manually create the `classes.txt` file (see [here](https://github.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/blob/main/doc/classes.txt) for an example of how it's formatted)."
      ],
      "metadata": {
        "id": "0c5Kdh0GmQHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python function to automatically create data.yaml config file\n",
        "# 1. Reads \"classes.txt\" file to get list of class names\n",
        "# 2. Creates data dictionary with correct paths to folders, number of classes, and names of classes\n",
        "# 3. Writes data in YAML format to data.yaml\n",
        "\n",
        "import yaml\n",
        "import os\n",
        "\n",
        "def create_data_yaml(path_to_classes_txt, path_to_data_yaml):\n",
        "\n",
        "  # Read class.txt to get class names\n",
        "  if not os.path.exists(path_to_classes_txt):\n",
        "    print(f'classes.txt file not found! Please create a classes.txt labelmap and move it to {path_to_classes_txt}')\n",
        "    return\n",
        "  with open(path_to_classes_txt, 'r') as f:\n",
        "    classes = []\n",
        "    for line in f.readlines():\n",
        "      if len(line.strip()) == 0: continue\n",
        "      classes.append(line.strip())\n",
        "  number_of_classes = len(classes)\n",
        "\n",
        "  # Create data dictionary\n",
        "  data = {\n",
        "      'path': '/content/data',\n",
        "      'train': 'train/images',\n",
        "      'val': 'validation/images',\n",
        "      'nc': number_of_classes,\n",
        "      'names': classes\n",
        "  }\n",
        "\n",
        "  # Write data to YAML file\n",
        "  with open(path_to_data_yaml, 'w') as f:\n",
        "    yaml.dump(data, f, sort_keys=False)\n",
        "  print(f'Created config file at {path_to_data_yaml}')\n",
        "\n",
        "  return\n",
        "\n",
        "# Define path to classes.txt and run function\n",
        "path_to_classes_txt = '/content/custom_data/classes.txt'\n",
        "path_to_data_yaml = '/content/data.yaml'\n",
        "\n",
        "create_data_yaml(path_to_classes_txt, path_to_data_yaml)\n",
        "\n",
        "print('\\nFile contents:\\n')\n",
        "!cat /content/data.yaml"
      ],
      "metadata": {
        "id": "4letvP7X12ji",
        "collapsed": true,
        "outputId": "8920fe83-4234-4594-9156-eb9a848d3671",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created config file at /content/data.yaml\n",
            "\n",
            "File contents:\n",
            "\n",
            "path: /content/data\n",
            "train: train/images\n",
            "val: validation/images\n",
            "nc: 7\n",
            "names:\n",
            "- aphids\n",
            "- lepidoptera\n",
            "- snails\n",
            "- slugs\n",
            "- mites\n",
            "- thrips\n",
            "- whiteflies\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myP80_bnTNMi"
      },
      "source": [
        "# 6.&nbsp;Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Training!"
      ],
      "metadata": {
        "id": "V17UjYU5ZQdR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bbpob1gTPlo",
        "outputId": "e1891cfb-9784-4889-a614-e8fd28e41f5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6.2MB 310.3MB/s 0.0s\n",
            "Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=60, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 120.5MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=7\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752677  ultralytics.nn.modules.head.Detect           [7, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,012,213 parameters, 3,012,197 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.4MB 260.0MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1015.1¬±353.0 MB/s, size: 31.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data/train/labels... 2726 images, 0 backgrounds, 93 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2726/2726 2.2Kit/s 1.2s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/1024_whiteflies-Large-population-of-B_-tabaci-adults-feeding-on-the-underside-of-a-young-cassava-leaf_jpg.rf.7ed6dc2c839bac32b114765dcd59d9e1.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/1603_0_jpg.rf.9b222935d5189a9ffeaa85a55c055584.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/1606_300x200_jpg.rf.4b93f2ae9646853bd87a3a42e999ff8b.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/1669_400x400_10_jpg.rf.554534ec5f868f9fd09b5518fcef5d6b.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/1WsL40XXudujiygZ8e0vtUQ_jpg.rf.09d5708c3c63f2bb717c1cd598ac441c.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/1_jpg.rf.a0735d0e4aa57136f481a2b3774b54d2.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/220px-Silverleaf_Whitefly_28Bemisia_tabaci29_adult_jpg.rf.dcf331399142662d99c282e03ba097eb.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/220px-Weisse-Fliege_jpg.rf.582255e267227b7b75b9e759fdd88007.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/2422jgnc_jpg.rf.d495cb82abf17c0f13a04ba1dccbd019.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/276_jpg.rf.c035b57c8b78cc04ae22e68068f41b44.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/3-s2_0-B9780124115842000068-f06-02-9780124115842_jpg.rf.02b5da34a61dad06ea17400a5e1abdc0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/323232_jpg.rf.810cac8479427c51c2113fcf6d53f737.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/6B35A41A9582C035CA6ADC1C5803AD7A_jpg.rf.98e45cb5a9502847640c53b2560efee5.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/800px-Bemisia_tabaci_from_USDA_2_jpg.rf.cbf77ec14ee4bf1530255781abf46c38.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/920_jpg.rf.992c0bb589f431a8dda3bec71323e035.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/921_300x200_jpg.rf.c1b7d5b3134dca29ae0ec3fba4b86e7f.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/947_300x200_jpg.rf.99c2742a06a203e2ee152cdd3d4819c9.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-1-_jpg.rf.b5d2871f4ab4cc70eddfb73ded28f202.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-10-_jpg.rf.fa10bfd1fcec31c5986e20338066a45d.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-12-_jpg.rf.885e5058de7e795cd1e74bddb663a83c.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-14-_jpg.rf.c3528eb501019936460492208b3ec6d7.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-15-_jpg.rf.d85b47a9a9363220b85ae202a72ee7db.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-17-_jpg.rf.65b26ebb1c4e69a69080dc683b4758f7.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-18-_jpg.rf.3768dd1c16d79ed70388084202d1830b.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-19-_jpg.rf.a15565651147666561b19e55b4367f2d.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-2-_jpg.rf.f1a9b4af4e55f68a245b605fed9354f9.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-21-_jpg.rf.71a93a161464f6113b8355d7fd522c34.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-22-_jpg.rf.193866399617731944b69da8393241fa.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-24-_jpg.rf.5cc7b1a30b8f3d24ec9f0567ef0e42cc.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-26-_jpg.rf.220508c33cf2563ae2b1e025ab99b163.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-27-_jpg.rf.8ed1b3553189e34552dfc96d27809a8e.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-28-_jpg.rf.2aa7be3c54bf074636b8f43a41b14ee0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-29-_jpg.rf.899788bd8129ec079be99a3002df1668.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-3-_jpg.rf.8bd75840d2421f49bd9e2997a8ee3328.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-30-_jpg.rf.0d30dfb26e3102bca58e97ae82d00952.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-32-_jpg.rf.e69b40d6e3731cf82a72d7c28a2532c4.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-33-_jpg.rf.1c0bdea0d4b63c4fa6e595e20844a00c.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-34-_jpg.rf.b20290aae132db6e3e51564817316962.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-35-_JPG.rf.1f6e2629412bd1567998794fa2a73255.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-36-_jpg.rf.5a81c607f8309b175d664cdf5be4815c.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-37-_JPG.rf.c8a99f66a623ce451367c290c348639c.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-38-_jpg.rf.54ea46dfa058272c5dc87f43cc97630e.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-39-_jpg.rf.069ade2194ba2cc03be7f95431372d8b.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-4-_JPG.rf.e752ee6863ee64c5ce0cd11d6a1e306f.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-40-_jpg.rf.520627ceff737b732e0b002447943c9c.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-41-_jpg.rf.4304bf75d86ebd7fb55fa1ae0ad4523d.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-42-_jpg.rf.07dd33a8819862e11cc287703a15ae92.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-43-_jpg.rf.a1c6c5650d8c24140f64b5bba47f80f3.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-44-_jpg.rf.6038525e1ff3d5225f8bf1707bfa851a.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-45-_jpg.rf.7bbc2111714fc2c21a9549b2ac7b64dd.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-46-_jpg.rf.27ab6a388a64fb0b65578b1d897b4289.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-48-_JPG.rf.9122acf357b0d865c7da1f01ce9885db.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-49-_JPG.rf.fd5eb46817eb7b8bdaf91707ca3fda2d.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-5-_JPG.rf.4def264fb83b0805242276b36b1fbb39.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-50-_JPG.rf.1583e2825dae54ba1838d76116a8da5a.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-51-_JPG.rf.93750f3fc1d9f8bddeed26ee6ab6dc5f.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-52-_JPG.rf.d9696a72fd83be1f4879541fb3d778f3.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-53-_JPG.rf.3c85621a501a4c78f04b5ec259c221c4.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-54-_JPG.rf.59ddcd8dc37c9d5c256f62efc69ffcff.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-55-_JPG.rf.b945672981f4c551c5cd6040204cd76a.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-56-_JPG.rf.b545b3f021a66a0f4af85f2b0c8ef1f0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-57-_JPG.rf.c950874bce5eea44551b5b118cf6882a.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-58-_JPG.rf.e435e39156e2884a81f8df5b8ed72701.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-59-_JPG.rf.f331e7f20a3aa36eb875fbb39cb16929.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-6-_jpg.rf.661e06de7ed1c07531ee310b743c8f95.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-60-_JPG.rf.b8654f4adb4dae5e61503acdff1b4ed8.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-7-_jpg.rf.1416b5a419f51b3681f805363bf83422.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-8-_jpg.rf.c8d7a8e94ef9f3d5648ae874c8695d65.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/BA-9-_jpg.rf.2db88ab4779ad481c234ea00708b7865.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/IMG_4667-495x400_jpg.rf.dbc2bf17f2f0474f5f5c372cb69e4a44.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/file-20170829-31699-ynn97f_jpg.rf.b7b0285b6099cef87ba1ebc7a771f3ca.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/hjhj_jpg.rf.29df613736ddbe02ef8763edbd7e7a35.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/image010_jpg.rf.192f8042f59bdf1b868f9101c1c3aa8d.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/image4_jpg.rf.85e75f4c07656d418751f3b09dab8797.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/images116_jpg.rf.304ff38e32480ae673c085da1ce2295d.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/images11_jpg.rf.6a918f194a32d5bab8a900f63eb32292.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/images140_jpg.rf.c3af3af8c1e708c5c283a0ab94a9b618.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/images191_jpg.rf.8140a6944c751f430f006924326e0636.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/images196_jpg.rf.c9f17bdf01d91625ba1c32f5a9dfbf51.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/images21_jpg.rf.a18ad29acc6b7d0264bc752a9a84aba4.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/images26_jpg.rf.465805a34eb2ba137f59e1917e30f231.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/images27_jpg.rf.6ecde739597d16bd4847977bb1eaf888.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/images34_jpg.rf.4aa0eb85a3ff293e0ab4dc49667fc03e.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/images39_jpg.rf.66790b79e1fc889ba9fac36d59569e06.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/images49_jpg.rf.7fcd581525595ed64a33f11c1639fa2d.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/images52_jpg.rf.3b5bb33ae540cd980d6fdc580423717a.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/images54_jpg.rf.b5a336d5d16164c7e63cada02d9409c0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/images59_jpg.rf.3b7615df3392671f50f97c797f75c28e.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/images6-2-_jpg.rf.22d29d0a0e1610d87f9fcd995f2c5802.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/images65_jpg.rf.f79abd696c8972021c0ee062a38f82e2.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/images67_jpg.rf.80174ee57c077eb31980bb073de263f4.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/images68_jpg.rf.6fcd8bf6cf388578aab00635d29ee97f.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/images70_jpg.rf.722ee6119248f766eb1df64e01c84412.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data/train/labels.cache\n",
            "WARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 254, len(boxes) = 4443. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 441.3¬±209.7 MB/s, size: 37.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data/validation/labels... 523 images, 0 backgrounds, 23 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 523/523 945.5it/s 0.6s\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/validation/images/220px-Weisse-Fliege_jpg.rf.582255e267227b7b75b9e759fdd88007.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/validation/images/2422jgnc_jpg.rf.d495cb82abf17c0f13a04ba1dccbd019.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/validation/images/276_jpg.rf.c035b57c8b78cc04ae22e68068f41b44.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/validation/images/323232_jpg.rf.810cac8479427c51c2113fcf6d53f737.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/validation/images/BA-1-_jpg.rf.b5d2871f4ab4cc70eddfb73ded28f202.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/validation/images/BA-10-_jpg.rf.fa10bfd1fcec31c5986e20338066a45d.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/validation/images/BA-15-_jpg.rf.d85b47a9a9363220b85ae202a72ee7db.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/validation/images/BA-19-_jpg.rf.a15565651147666561b19e55b4367f2d.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/validation/images/BA-27-_jpg.rf.8ed1b3553189e34552dfc96d27809a8e.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/validation/images/BA-34-_jpg.rf.b20290aae132db6e3e51564817316962.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/validation/images/BA-36-_jpg.rf.5a81c607f8309b175d664cdf5be4815c.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/validation/images/BA-4-_JPG.rf.e752ee6863ee64c5ce0cd11d6a1e306f.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/validation/images/BA-46-_jpg.rf.27ab6a388a64fb0b65578b1d897b4289.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/validation/images/BA-50-_JPG.rf.1583e2825dae54ba1838d76116a8da5a.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/validation/images/BA-51-_JPG.rf.93750f3fc1d9f8bddeed26ee6ab6dc5f.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/validation/images/BA-54-_JPG.rf.59ddcd8dc37c9d5c256f62efc69ffcff.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/validation/images/BA-56-_JPG.rf.b545b3f021a66a0f4af85f2b0c8ef1f0.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/validation/images/BA-59-_JPG.rf.f331e7f20a3aa36eb875fbb39cb16929.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/validation/images/IMG_4667-495x400_jpg.rf.dbc2bf17f2f0474f5f5c372cb69e4a44.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/validation/images/images116_jpg.rf.304ff38e32480ae673c085da1ce2295d.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/validation/images/images11_jpg.rf.6a918f194a32d5bab8a900f63eb32292.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/validation/images/images140_jpg.rf.c3af3af8c1e708c5c283a0ab94a9b618.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/validation/images/images59_jpg.rf.3b7615df3392671f50f97c797f75c28e.jpg: ignoring corrupt image/label: Label class 7 exceeds dataset class count 7. Possible class labels are 0-6\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/data/validation/labels.cache\n",
            "WARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 68, len(boxes) = 801. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to /content/runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/train\u001b[0m\n",
            "Starting training for 60 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/60      2.34G      1.657      3.231      1.896         25        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 165/165 3.2it/s 52.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 2.4it/s 6.6s\n",
            "                   all        500        801      0.228        0.3      0.226     0.0969\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/60      2.74G      1.684      2.665      1.907         29        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 165/165 3.5it/s 47.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 2.7it/s 5.9s\n",
            "                   all        500        801      0.256      0.288      0.212     0.0801\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/60      2.76G      1.718      2.474      1.885         27        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 165/165 3.5it/s 46.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 2.9it/s 5.6s\n",
            "                   all        500        801      0.379      0.436      0.358      0.151\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/60      2.77G      1.717      2.389      1.904         21        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 165/165 3.6it/s 46.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 2.9it/s 5.4s\n",
            "                   all        500        801      0.435      0.334      0.337      0.151\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/60      2.78G      1.713      2.291      1.868         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 165/165 3.6it/s 45.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 2.5it/s 6.5s\n",
            "                   all        500        801      0.226      0.357      0.242      0.103\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/60      2.81G      1.674      2.163      1.859         30        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 165/165 3.5it/s 47.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 2.9it/s 5.5s\n",
            "                   all        500        801      0.571      0.466      0.451       0.21\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/60      3.05G       1.66      2.111      1.814         23        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 165/165 3.5it/s 46.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 2.8it/s 5.7s\n",
            "                   all        500        801      0.457      0.536      0.507      0.233\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/60      3.06G      1.642      2.008      1.803         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 165/165 3.5it/s 46.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 2.9it/s 5.6s\n",
            "                   all        500        801      0.502      0.539      0.501      0.229\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/60      3.07G      1.626      1.974      1.792         28        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 165/165 3.6it/s 46.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 2.7it/s 5.9s\n",
            "                   all        500        801       0.62      0.558      0.584      0.302\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/60       3.1G      1.586      1.887      1.764         33        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 165/165 3.4it/s 48.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 3.7it/s 4.3s\n",
            "                   all        500        801      0.624       0.63      0.648      0.336\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/60      3.12G      1.598      1.842      1.766         33        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 165/165 3.4it/s 48.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 3.0it/s 5.3s\n",
            "                   all        500        801      0.647      0.607      0.677       0.36\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/60      3.13G      1.574        1.8      1.745         21        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 165/165 3.4it/s 48.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 3.4it/s 4.7s\n",
            "                   all        500        801      0.639      0.675      0.685      0.368\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/60      3.14G      1.572      1.801      1.755         23        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 165/165 3.4it/s 48.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 3.0it/s 5.3s\n",
            "                   all        500        801      0.709      0.608      0.685      0.368\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/60      3.17G      1.543      1.775      1.731         22        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 165/165 3.4it/s 48.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 3.5it/s 4.5s\n",
            "                   all        500        801      0.723      0.636      0.721      0.389\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/60      3.18G      1.525      1.715      1.715         31        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 165/165 3.3it/s 49.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 3.5it/s 4.6s\n",
            "                   all        500        801      0.769       0.68      0.756      0.427\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/60       3.2G      1.525      1.688      1.709         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 165/165 3.4it/s 48.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 3.5it/s 4.5s\n",
            "                   all        500        801      0.699      0.726      0.726      0.394\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/60      3.21G      1.517      1.655      1.704         22        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 165/165 3.4it/s 48.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 2.9it/s 5.5s\n",
            "                   all        500        801      0.754      0.682      0.765      0.439\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/60      3.24G       1.52      1.643      1.706         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 165/165 3.4it/s 48.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 3.7it/s 4.4s\n",
            "                   all        500        801      0.672      0.632      0.687      0.389\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/60      3.25G      1.496      1.611      1.675         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 165/165 3.3it/s 50.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 3.6it/s 4.5s\n",
            "                   all        500        801      0.757      0.679      0.758      0.434\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/60      3.27G      1.496      1.571      1.682         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 165/165 3.4it/s 48.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 3.4it/s 4.7s\n",
            "                   all        500        801      0.728      0.762      0.799       0.46\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/60      3.28G      1.493      1.595      1.658         52        640: 10% ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 17/165 3.6it/s 5.0s<41.5s"
          ]
        }
      ],
      "source": [
        "!yolo detect train data=/content/data.yaml model=yolov8n.pt epochs=60 imgsz=640"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo8BJRXeg0Ap"
      },
      "source": [
        "#7.&nbsp;Test Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PooP5Vjsg2Jn",
        "outputId": "5fcfef45-8218-4f14-8fe5-4a638d054190",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: yolo: command not found\n"
          ]
        }
      ],
      "source": [
        "!yolo detect predict model=runs/detect/train/weights/best.pt source=data/validation/images save=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEEObQqoiGrs"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from IPython.display import Image, display\n",
        "for image_path in glob.glob(f'/content/runs/detect/predict/*.jpg')[:10]:\n",
        "  display(Image(filename=image_path, height=400))\n",
        "  print('\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7yrFRViVczX"
      },
      "source": [
        "#7.&nbsp;Deploy Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.1 Download YOLO Model\n",
        "\n",
        "First, zip and download the trained model by running the code blocks below.\n",
        "\n",
        "The code creates a folder named `my_model`, moves the model weights into it, and renames them from `best.pt` to `my_model.pt`. It also adds the training results in case you want to reference them later. It then zips the folder as `my_model.zip`."
      ],
      "metadata": {
        "id": "IcoBAeHXa86W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create \"my_model\" folder to store model weights and train results\n",
        "!mkdir /content/my_model\n",
        "!cp /content/runs/detect/train/weights/best.pt /content/my_model/my_model.pt\n",
        "!cp -r /content/runs/detect/train /content/my_model\n",
        "\n",
        "# Zip into \"my_model.zip\"\n",
        "%cd my_model\n",
        "!zip /content/my_model.zip my_model.pt\n",
        "!zip -r /content/my_model.zip train\n",
        "%cd /content"
      ],
      "metadata": {
        "id": "qcBdnOA9v85S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43ypwonynLVu"
      },
      "outputs": [],
      "source": [
        "# This takes forever for some reason, you can also just download the model from the sidebar\n",
        "from google.colab import files\n",
        "\n",
        "files.download('/content/my_model.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.2 Deploy YOLO Model on Local Devices\n",
        "\n",
        "Next, we'll take our downloaded model and run it on a local device. This section provides instructions showing how to deploy YOLO models on various devices.\n",
        "\n",
        "I wrote a basic Python script, `yolo_detect.py`, that shows how to load a model, run inference on an image source, parse the inference results, and display boxes around each detected class in the image. The [script](https://github.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/blob/main/yolo_detect.py) gives an example of how to work with Ultralytics YOLO models in Python, and it can be used as a starting point for more advanced applications."
      ],
      "metadata": {
        "id": "YL06c6pb_UqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2.1 Deploy on PC (Windows, Linux, or macOS)\n",
        "\n",
        "The easiest way to run Ultralytics models on a PC is using Anaconda. Anaconda sets up a virtual Python environment and allows you to easily install Ultralytics and PyTorch. It automatically installs CUDA and cuDNN, which allows you to speed up model inference with your NVIDIA GPU.\n",
        "\n",
        "> **NOTE:** My YouTube video (link to be added) shows how to deploy your model on a PC. It walks through the following steps, so watch the video if you prefer having visual instructions.\n",
        "\n",
        "**1. Download and Install Anaconda**\n",
        "\n",
        "Go to the Anaconda download page at https://anaconda.com/download, click the ‚Äúskip registration‚Äù button, and then download the package for your OS. When it's finished downloading, run the installer and click through the installation steps. You can use the default options for installation.\n",
        "\n",
        "**2. Set up virtual environment**\n",
        "\n",
        "Once it's installed, run Anaconda Prompt from the Start Bar. (If you're on macOS or Linux, just open a command terminal).\n",
        "\n",
        "Issue the following commands to create a new Python environment and activate it:\n",
        "\n",
        "```\n",
        "conda create --name yolo-env1 python=3.12 -y\n",
        "conda activate yolo-env1\n",
        "```\n",
        "\n",
        "Install Ultralytics (which also installs import libraries like OpenCV-Python, Numpy, and PyTorch) by issuing the following command:\n",
        "\n",
        "```\n",
        "pip install ultralytics\n",
        "```\n",
        "\n",
        "If you have an NVIDIA GPU, you can install the GPU-enabled version of PyTorch by issuing the following command:\n",
        "\n",
        "```\n",
        "pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
        "```\n",
        "\n",
        "**3. Extract downloaded model**\n",
        "Take the `my_model.zip` file you downloaded in Step 7.1 and unzip it to a folder on your PC. In the Anaconda Prompt terminal, move into the unzipped folder using:\n",
        "\n",
        "```\n",
        "cd path/to/folder\n",
        "```\n",
        "\n",
        "**4. Download and run yolo_detect.py**\n",
        "\n",
        "Download the `yolo_detect.py` script into the `my_model` folder using:\n",
        "\n",
        "```\n",
        "curl -o yolo_detect.py https://raw.githubusercontent.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/refs/heads/main/yolo_detect.py\n",
        "```\n",
        "\n",
        "Alright! We're ready to run the script. To run inference with a yolov8s model on a USB camera at 1280x720 resolution, issue:\n",
        "\n",
        "```\n",
        "python yolo_detect.py --model my_model.pt --source usb0 --resolution 1280x720\n",
        "```\n",
        "\n",
        "A window will appear showing a live feed from your webcam with boxes drawn around detected objects in each frame.\n",
        "\n",
        "You can also run the model on an video file, image, or folder of images. To see a full list of arguments for `yolo_detect.py`, issue `python yolo_detect.py --help` or see the [README file](https://github.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/blob/main/README.md).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gzaJQ2sGEPhP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2.2 Deploy on Raspberry Pi\n",
        "\n",
        "Keep an eye out for an article showing how to convert YOLO models to NCNN format and run them on the Raspberry Pi!"
      ],
      "metadata": {
        "id": "GelkpRLPEYmJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.&nbsp;Conclusion"
      ],
      "metadata": {
        "id": "y8fOJ4g8Q5x0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congratulations! You've successfully trained and deployed a YOLO object detection model. üòÄ\n",
        "\n",
        "Next, you can extend your application beyond just drawing boxes and counting objects. Add functionality like logging the number of objects detected over time or taking a picture when certain objects are detected. Check out some example applications at our GitHub repository: https://github.com/EdjeElectronics/Train-and-Deploy-YOLO-Models\n",
        "\n",
        "Thanks for working through this notebook, and good luck with your projects!"
      ],
      "metadata": {
        "id": "DEZGuG1-Peg5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Appendix: Common Errors"
      ],
      "metadata": {
        "id": "fXeDs6SaQBRy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you run into any errors working through this notebook, please do the following:\n",
        "\n",
        "\n",
        "- Double-check that the dataset files are set up in the correct folder structure\n",
        "- Make sure there are no typos or errors in your labelmap file\n",
        "- Google search the error to look for solutions\n",
        "\n",
        "If none of those help, please submit an [Issue](https://github.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/issues) on the GitHub page. In this section, I will add resolutions to common errors as they come up."
      ],
      "metadata": {
        "id": "Q19ENCHRQOCH"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}